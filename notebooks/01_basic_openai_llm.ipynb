{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54e03332-3cd4-4815-a1b5-f066ceebe4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in d:\\workspace\\ai-dev\\multimodel-langchain-rag-langgraph-ai-expert\\.venv\\lib\\site-packages (1.95.1)\n",
      "Requirement already satisfied: python-dotenv in d:\\workspace\\ai-dev\\multimodel-langchain-rag-langgraph-ai-expert\\.venv\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\workspace\\ai-dev\\multimodel-langchain-rag-langgraph-ai-expert\\.venv\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\workspace\\ai-dev\\multimodel-langchain-rag-langgraph-ai-expert\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\workspace\\ai-dev\\multimodel-langchain-rag-langgraph-ai-expert\\.venv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\workspace\\ai-dev\\multimodel-langchain-rag-langgraph-ai-expert\\.venv\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\workspace\\ai-dev\\multimodel-langchain-rag-langgraph-ai-expert\\.venv\\lib\\site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in d:\\workspace\\ai-dev\\multimodel-langchain-rag-langgraph-ai-expert\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\workspace\\ai-dev\\multimodel-langchain-rag-langgraph-ai-expert\\.venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in d:\\workspace\\ai-dev\\multimodel-langchain-rag-langgraph-ai-expert\\.venv\\lib\\site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\workspace\\ai-dev\\multimodel-langchain-rag-langgraph-ai-expert\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in d:\\workspace\\ai-dev\\multimodel-langchain-rag-langgraph-ai-expert\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\workspace\\ai-dev\\multimodel-langchain-rag-langgraph-ai-expert\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\workspace\\ai-dev\\multimodel-langchain-rag-langgraph-ai-expert\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\workspace\\ai-dev\\multimodel-langchain-rag-langgraph-ai-expert\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\workspace\\ai-dev\\multimodel-langchain-rag-langgraph-ai-expert\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\workspace\\ai-dev\\multimodel-langchain-rag-langgraph-ai-expert\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: colorama in d:\\workspace\\ai-dev\\multimodel-langchain-rag-langgraph-ai-expert\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install LangChain and OpenAI integration\n",
    "%pip install -U openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6226a65e-43c4-41ea-b64e-2bd287a0698b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY is set.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# You can do this in your terminal before starting Jupyter:\n",
    "# export OPENAI_API_KEY='your_api_key_here' #(Linux/macOS)\n",
    "# $env:OPENAI_API_KEY='your_api_key_here' (PowerShell)\n",
    "#\n",
    "# If you must set it directly in the notebook (NOT recommended for production):\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR_ACTUAL_OPENAI_API_KEY\"\n",
    "\n",
    "# Verify API key is set\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    print(\"WARNING: OPENAI_API_KEY environment variable not set.\")\n",
    "    print(\"Please set it before proceeding, or uncomment the line above to set it directly (not recommended).\")\n",
    "else:\n",
    "    print(\"OPENAI_API_KEY is set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7919350-be0f-4d2a-8599-6db558e1e27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded system prompt from 'prompt.txt'\n",
      "Historical Expert's Response:\n",
      "The Leaning Tower of Pisa, one of Italy's most famous landmarks, began tilting during its construction in the 12th century due to several historical and engineering reasons:\n",
      "\n",
      "1. **Soft Soil:** The tower's foundation was laid on a soft ground composed of sand, clay, and shells. This unstable subsoil caused the tower to start leaning even before the construction reached the third floor.\n",
      "\n",
      "2. **Design Flaws:** The original design of the tower did not account for the soft ground or the weight of the structure. The uneven settling of the foundation on different sides caused the tilt to worsen.\n",
      "\n",
      "3. **Wars and Interruptions:** During the tower's construction in the 12th and 13th centuries, several wars broke out, leading to long pauses in construction. These interruptions allowed the soil to settle unevenly, exacerbating the tilt.\n",
      "\n",
      "Efforts to stabilize the Leaning Tower of Pisa have been ongoing throughout history. Some key engineering interventions include:\n",
      "\n",
      "- **19th Century Interventions:** In the 19th century, engineers attempted to counteract the lean by removing soil from the higher side and adding weights to the lower side. These efforts helped reduce the tilt slightly.\n",
      "\n",
      "- **20th Century Interventions:** In the late 20th century, extensive restoration work was carried out to stabilize the tower. This included the insertion of metal rods and counterweights to prevent further leaning.\n",
      "\n",
      "- **Ongoing Monitoring:** Modern engineering techniques are continuously used to monitor and stabilize the tower. Instruments have been installed to track the tower's movement, and periodic maintenance is performed to ensure its structural integrity.\n",
      "\n",
      "Despite the numerous efforts to stabilize the tower, its distinctive lean remains part of its charm and attracts millions of visitors each year. The collaboration between historical understanding and modern engineering methods has helped preserve this iconic structure for generations to come. If you have any more questions about historical landmarks or architectural marvels, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "client = OpenAI(\n",
    "  api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "prompt_file_path = \"prompt.txt\" # Make sure this path is correct\n",
    "\n",
    "# --- Load System Prompt from File ---\n",
    "try:\n",
    "    with open(prompt_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        system_prompt_content = file.read()\n",
    "    print(f\"Successfully loaded system prompt from '{prompt_file_path}'\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{prompt_file_path}' was not found at '{os.path.abspath(prompt_file_path)}'. Please create it or provide the correct path.\")\n",
    "    exit() # Exit if the prompt file isn't found\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while reading the file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Define the system message using content from the file\n",
    "system_message = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": system_prompt_content\n",
    "}\n",
    "\n",
    "# Define the system role for the \"Helpful Historical Expert\"\n",
    "#system_message = {\n",
    "#    \"role\": \"system\",\n",
    "#    \"content\": \"You are a helpful historical expert, specializing in architectural history and ancient engineering. You provide accurate, detailed, and engaging information.\"\n",
    "#}\n",
    "\n",
    "# Define the user's question about the Leaning Tower of Pisa\n",
    "user_question = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"What are the primary historical reasons for the Leaning Tower of Pisa's tilt, and what engineering efforts have been made to stabilize it over the centuries?\"\n",
    "}\n",
    "\n",
    "# Create the chat completion\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",  #\"gpt-4\" # You can also use \"gpt-3.5-turbo\" for a faster, cheaper option\n",
    "        messages=[\n",
    "            system_message,\n",
    "            user_question\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Access and print the model's response\n",
    "    if response.choices:\n",
    "        for choice in response.choices:\n",
    "            print(f\"Historical Expert's Response:\\n{choice.message.content}\")\n",
    "    else:\n",
    "        print(\"No response choices found.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "808b4ea1-98e9-433a-ad82-42df54cc5a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Asking the historical question (Leaning Tower of Pisa) ---\n",
      "\n",
      "\n",
      "Historical Expert's Response:\n",
      "\n",
      "The Leaning Tower of Pisa, known for its distinctive tilt, has been a subject of fascination for centuries. The primary historical reasons for its tilt are as follows:\n",
      "\n",
      "- **Foundation on Unstable Soil**: The tower was built on soft ground composed of clay, fine sand, and shells, causing uneven settling of the foundation during construction.\n",
      "\n",
      "- **Construction Halts**: Work on the tower began in 1173 but was interrupted several times due to wars and financial difficulties. These pauses allowed the underlying soil to settle unevenly, exacerbating the tilt.\n",
      "\n",
      "- **Design Flaws**: The tower's initial design did not account for the soft ground conditions, lack of a strong foundation, and the weight of the tower, contributing to its lean.\n",
      "\n",
      "Over the centuries, various engineering efforts have been undertaken to stabilize the Leaning Tower of Pisa:\n",
      "\n",
      "- **Historical Interventions**:\n",
      "  - **Inclination Correction**: In the early stages of construction, builders attempted to compensate for the lean by making the columns on one side taller than those on the opposite side. This unintentionally increased the tilt.\n",
      "\n",
      "- **Modern Stabilization Efforts**:\n",
      "  - **Soil Extraction**: In the late 1990s, engineers extracted soil from underneath the tower's foundation to reduce the tilt by about 17 inches (45 cm).\n",
      "  - **Counterweights**: Engineers also added counterweights on the north side of the tower to help offset the lean and prevent further tilting.\n",
      "  \n",
      "Despite these interventions, the tower continues to lean, albeit at a safer angle than before. It now stands as a testament to both medieval architecture and the challenges of building on unstable ground.\n",
      "\n",
      "If you would like more detailed information or have any other historical or architectural inquiries, feel free to ask!\n",
      "\n",
      "--- Asking an off-topic question (stock market) to test guardrails ---\n",
      "\n",
      "\n",
      "Historical Expert's Response:\n",
      "\n",
      "As a Historical Expert, I specialize in providing information related to history, architecture, and engineering. I must inform you that I am not qualified to offer advice on contemporary financial matters, such as stock investments or market trends. It's crucial to consult with a certified financial advisor or conduct thorough research on current market conditions before making any investment decisions. If you have any questions related to history, architecture, or engineering, feel free to ask, and I'll be more than happy to assist you.\n"
     ]
    }
   ],
   "source": [
    "# Define the user's question about the Leaning Tower of Pisa\n",
    "user_question_pisa = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"What are the primary historical reasons for the Leaning Tower of Pisa's tilt, and what engineering efforts have been made to stabilize it over the centuries?\"\n",
    "}\n",
    "\n",
    "# Define a user's question that should be declined (out of scope)\n",
    "user_question_off_topic = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"Tell me the best stock to invest in today, July 12, 2025.\"\n",
    "}\n",
    "\n",
    "# --- Make the API Call for the historical question ---\n",
    "print(\"\\n--- Asking the historical question (Leaning Tower of Pisa) ---\\n\\n\")\n",
    "try:\n",
    "    response_pisa = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",  #\"gpt-4\"\n",
    "        messages=[\n",
    "            system_message,\n",
    "            user_question_pisa\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if response_pisa.choices:\n",
    "        for choice in response_pisa.choices:\n",
    "            print(f\"Historical Expert's Response:\\n\\n{choice.message.content}\")\n",
    "    else:\n",
    "        print(\"No response choices found for the historical question.\\n\\n\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during the historical API call: {e}\")\n",
    "\n",
    "\n",
    "# --- Make the API Call for the off-topic question to test guardrails ---\n",
    "print(\"\\n--- Asking an off-topic question (stock market) to test guardrails ---\\n\\n\")\n",
    "try:\n",
    "    response_off_topic = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",  #\"gpt-4\"\n",
    "        messages=[\n",
    "            system_message,\n",
    "            user_question_off_topic\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if response_off_topic.choices:\n",
    "        for choice in response_off_topic.choices:\n",
    "            print(f\"Historical Expert's Response:\\n\\n{choice.message.content}\")\n",
    "    else:\n",
    "        print(\"No response choices found for the off-topic question.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during the off-topic API call: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c3485a-3594-4302-b574-7a685050fa43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
